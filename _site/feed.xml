<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>weiSupreme</title>
		<description>zhuwei的个人网站！</description>
		<link>http://localhost:4000</link>
		<atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>目标检测可能的研究方向</title>
				<description>&lt;p&gt;  此博客主要收集来自&lt;a href=&quot;https://www.zhihu.com/question/64861580&quot;&gt;知乎&lt;/a&gt;的问答。&lt;/p&gt;

&lt;p&gt;1.提升图像分辨率。 如果不考虑context， CNN能识别出物体大小不应小于20x20 pixels.&lt;/p&gt;

&lt;p&gt;2.观察目标， 设定合适大小的context， 不宜太小或者太大。&lt;/p&gt;

&lt;p&gt;3.ROI pooling 会引入位置偏差， 物体越小， 偏差越明显。&lt;/p&gt;

&lt;p&gt;4.多引入一些low-level feature map，即做feature fusion。 小物体在高层的feature map上不能被很好表达。&lt;/p&gt;

&lt;p&gt;5.目标较小，建议作者用ROI Align 代替ROI pooling，ROI pooling在小物体上会带来较大误差，可以看看mask rcnn的分析&lt;/p&gt;

&lt;p&gt;6.把gt放大一点，加上上下文context，变相加大object,因为物体太小，上下文信息有助于找得更准&lt;/p&gt;

&lt;p&gt;7.如果对速度要求不高，考虑切图&lt;/p&gt;

&lt;p&gt;8.stride上考虑用一下hypernet(16cvpr)，降为8，速度会比较慢&lt;/p&gt;

&lt;p&gt;9.设置更合理的anchor size，避免出现“田”字，anchor没有覆盖中间的区域			
10.tiny faces, 上采样&lt;/p&gt;

&lt;p&gt;11.如果目标太小的话，不建议用图像检测的方案，试试分割可能效果更好			
12.FPN是否是一个值得尝试的方向？&lt;/p&gt;
</description>
				<pubDate>Thu, 31 May 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/informalessay/2018/05/31/object-detection-research-derection.html</link>
				<guid isPermaLink="true">http://localhost:4000/informalessay/2018/05/31/object-detection-research-derection.html</guid>
			</item>
		
			<item>
				<title>ubuntu16.04安装cuda8.0和cudnn5.1</title>
				<description>&lt;h1 id=&quot;禁用nouveal自带驱动可选推荐&quot;&gt;禁用nouveal自带驱动(可选，推荐)&lt;/h1&gt;

&lt;p&gt;  控制台输入命令，创建一个文件通过命令&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo vim /etc/modprobe.d/blacklist-nouveau.conf&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;并添加如下内容：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;blacklist nouveau&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;options nouveau modeset=0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;更新一下：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo update-initramfs -u&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;然后重启系统。再输入命令：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;lsmod | grep nouveau&lt;/code&gt;			
如果不显示任何信息，代表禁用成功。接着进行下一步。&lt;/p&gt;

&lt;h1 id=&quot;安装gpu驱动&quot;&gt;安装GPU驱动&lt;/h1&gt;

&lt;p&gt;  Ctrl+Alt+F1进入控制台，输入以下命令：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo services lightdm stop&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo add-apt-repository ppa:graphics-drivers/ppa&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get updates&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install nvidia-384&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install mesa-common-dev&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install freeglut3-dev&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo reboot&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其中 ‘nvidia-384’ 是驱动版本，上官网查询对应GPU型号的驱动即可。通过 ‘nvidia-smi’ 命令可以查看驱动是否正确安装。重启后可以正常使用图形界面。如果重启后分辨率有问题，请参考&lt;a href=&quot;http://http://gwang-cv.github.io/2016/10/21/Ubuntu16.04+Titan%20X+CUDA8.0+cudnn5/&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;cuda安装&quot;&gt;CUDA安装&lt;/h1&gt;
&lt;h2 id=&quot;首先安装缺少的依赖包强烈推荐避免之后的安装出问题&quot;&gt;首先安装缺少的依赖包（强烈推荐，避免之后的安装出问题）&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libgl1-mesa-dev libglu1-mesa libglu1-mesa-dev libxi-dev&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;安装执行文件&quot;&gt;安装执行文件&lt;/h2&gt;

&lt;p&gt;  从英伟达驱动官网下载对应的cuda驱动程序，如cuda8.0，选择 ‘run’ 可执行文件下载。下载完成后输入命令安装：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo sh cuda8.0***.run&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;首先是大段大段的协议，一直按 NETER 即可，注意 “more(%)”。选择 “accept“ 接受，接下来根据提示安装。==&lt;strong&gt;注意：当询问是否安装 cuda toolkit, cuda-exampls 时选择yes， 询问是否安装其他驱动时一定要选择no。&lt;/strong&gt;==其余如安装路径等默认即可&lt;/p&gt;

&lt;p&gt;  设置环境变量，输入命令：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo gedit ~/.bashrc&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;export PATH=/usr/local/cuda-8.0/bin:$PATH &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;export LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64:$LD_LIBRARY_PATH&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;export CUDA_HOME=/usr/local/cuda&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo source ~/.bashrc &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo ldconfig&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;  检测cuda是否配置正确。输入命令： ‘nvcc –version’ ，如果出现cuda版本信息等则说明安装正确。&lt;/p&gt;

&lt;p&gt;还可以继续测试cuda的samples.参考&lt;a href=&quot;http://www.cnblogs.com/xuliangxing/p/7575586.html&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;安装cudnn&quot;&gt;安装cudnn&lt;/h1&gt;
&lt;p&gt;  首先到官网下载对应版本的cudnn。安装cudnn比较简单，简单地说，就是复制几个文件：库文件和头文件。将cudnn的头文件复制到cuda安装路径的include路径下，将cudnn的库文件复制到cuda安装路径的lib64路径下。具体操作如下：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tar -zxvf cudnn-8.0-linux-x64-v7.tgz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cd cuda&lt;/code&gt;  （就是刚刚解压出来的文件夹)&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo cp /include/cudnn.h  /usr/local/cuda/include/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo cp lib64/*  /usr/local/cuda/lib64/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo chmod a+r /usr/local/cuda/include/cudnn.h&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo chmod a+r /usr/local/cuda/lib64/libcudnn*&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cd /usr/local/cuda/lib64/ &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo rm -rf libcudnn.so libcudnn.so.7&lt;/code&gt;  (#删除原有动态文件，版本号注意变化，可在cudnn的lib64文件夹中查看)&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo ln -s libcudnn.so.7.0.2 libcudnn.so.7&lt;/code&gt;   (生成软衔接（注意这里要和自己下载的cudnn版本对应，可以在/usr/local/cuda/lib64下查看自己libcudnn的版本）)&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo ln -s libcudnn.so.7 libcudnn.so&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sudo ldconfig -v&lt;/code&gt;  (立刻生效)&lt;/p&gt;

&lt;p&gt;  查看安装cudnn后cuda是否依旧可用：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nvcc --version&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这样，cudnn就安装完成了。如果要进一步验证，请参考&lt;a href=&quot;http://www.cnblogs.com/xuliangxing/p/7575586.html&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;参考链接&quot;&gt;参考链接&lt;/h1&gt;

&lt;p&gt;  和前面的有重复：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/xuliangxing/p/7575586.html&quot;&gt;1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/002ece426793&quot;&gt;2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://gwang-cv.github.io/2016/10/21/Ubuntu16.04+Titan%20X+CUDA8.0+cudnn5/&quot;&gt;3&lt;/a&gt;&lt;/p&gt;

</description>
				<pubDate>Sun, 20 May 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/tutorial/2018/05/20/ubuntu16.04-cuda8.0-cudnn5.1.html</link>
				<guid isPermaLink="true">http://localhost:4000/tutorial/2018/05/20/ubuntu16.04-cuda8.0-cudnn5.1.html</guid>
			</item>
		
			<item>
				<title>一些检测方面论文的翻译(转载博客)</title>
				<description>&lt;p&gt;  &lt;a href=&quot;https://blog.csdn.net/u011534057/article/details/51259812&quot;&gt;Faster R-CNN&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://blog.csdn.net/Ai_Smith/article/details/52997456?locationNum=2&amp;amp;fps=1&quot;&gt;SSD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://blog.csdn.net/hrsstudy/article/details/70305791&quot;&gt;YOLO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://blog.csdn.net/weixin_35654926/article/details/72473024&quot;&gt;YOLOv2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;  &lt;a href=&quot;https://blog.csdn.net/baobei0112/article/details/79754058&quot;&gt;YOLOv3&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Mon, 30 Apr 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/translation/2018/04/30/detection-paper-translation.html</link>
				<guid isPermaLink="true">http://localhost:4000/translation/2018/04/30/detection-paper-translation.html</guid>
			</item>
		
			<item>
				<title>SSD references</title>
				<description>&lt;p&gt;  &lt;a href=&quot;http://blog.csdn.net/xunan003/article/details/79089280&quot;&gt;ssd_pascal.py details&lt;/a&gt;			
  &lt;a href=&quot;http://blog.csdn.net/xunan003/article/details/79186162&quot;&gt;default box generation&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Thu, 22 Mar 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/informalessay/2018/03/22/SSD-references.html</link>
				<guid isPermaLink="true">http://localhost:4000/informalessay/2018/03/22/SSD-references.html</guid>
			</item>
		
			<item>
				<title>用电脑自动玩微信跳一跳</title>
				<description>&lt;p&gt;  用opencv和python写的自动玩微信跳一跳的代码，参考自网上的博客，下面是代码。&lt;a href=&quot;/assets/sources/wechat_jump_jump-master.zip&quot;&gt;点击这里下载所有文件和代码				
&lt;/a&gt;						
  电脑安装adb驱动，手机打开开发者选项里的usb调试开关，用数据线连接手机和电脑。打开微信跳一跳，开始游戏（不要自己跳，转到游戏界面就可以），然后运行play.py（python play.py），然后就看到程序自己在跳了。最后就可以尽情地刷分了！！！&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import os
import cv2
import numpy as np
import time
import random

# 使用的Python库及对应版本：
# python 3.6
# opencv-python 3.3.0
# numpy 1.13.3
# 用到了opencv库中的模板匹配和边缘检测功能

def get_screenshot(id):
	os.system('adb shell screencap -p /sdcard/%s.png' % str(id))
	os.system('adb pull /sdcard/%s.png .' % str(id))

def jump(distance):
	# 这个参数还需要针对屏幕分辨率进行优化
	press_time = int(distance * 1.35)

	# 生成随机手机屏幕模拟触摸点
	# 模拟触摸点如果每次都是同一位置，成绩上传可能无法通过验证
	rand = random.randint(0, 9) * 10
	cmd = ('adb shell input swipe %i %i %i %i ' + str(press_time)) \
		  % (320 + rand, 410 + rand, 320 + rand, 410 + rand)
	os.system(cmd)
	print(cmd)

def get_center(img_canny, ):
	# 利用边缘检测的结果寻找物块的上沿和下沿
	# 进而计算物块的中心点
	y_top = np.nonzero([max(row) for row in img_canny[400:]])[0][0] + 400
	x_top = int(np.mean(np.nonzero(canny_img[y_top])))

	y_bottom = y_top + 50
	for row in range(y_bottom, H):
		if canny_img[row, x_top] != 0:
			y_bottom = row
			break

	x_center, y_center = x_top, (y_top + y_bottom) // 2
	return img_canny, x_center, y_center

# 第一次跳跃的距离是固定的
jump(530)
time.sleep(1)

# 匹配小跳棋的模板
temp1 = cv2.imread('temp_player.jpg', 0)
w1, h1 = temp1.shape[::-1]
# 匹配游戏结束画面的模板
temp_end = cv2.imread('temp_end.jpg', 0)
# 匹配中心小圆点的模板
temp_white_circle = cv2.imread('temp_white_circle.jpg', 0)
w2, h2 = temp_white_circle.shape[::-1]

# 循环直到游戏失败结束
for i in range(10000):
	get_screenshot(0)
	img_rgb = cv2.imread('%s.png' % 0, 0)

	# 如果在游戏截图中匹配到带&quot;再玩一局&quot;字样的模板，则循环中止
	res_end = cv2.matchTemplate(img_rgb, temp_end, cv2.TM_CCOEFF_NORMED)
	if cv2.minMaxLoc(res_end)[1] &amp;gt; 0.95:
		print('Game over!')
		break

	# 模板匹配截图中小跳棋的位置
	res1 = cv2.matchTemplate(img_rgb, temp1, cv2.TM_CCOEFF_NORMED)
	min_val1, max_val1, min_loc1, max_loc1 = cv2.minMaxLoc(res1)
	center1_loc = (max_loc1[0] + 39, max_loc1[1] + 189)

	# 先尝试匹配截图中的中心原点，
	# 如果匹配值没有达到0.95，则使用边缘检测匹配物块上沿
	res2 = cv2.matchTemplate(img_rgb, temp_white_circle, cv2.TM_CCOEFF_NORMED)
	min_val2, max_val2, min_loc2, max_loc2 = cv2.minMaxLoc(res2)
	if max_val2 &amp;gt; 0.95:
		print('found white circle!')
		x_center, y_center = max_loc2[0] + w2 // 2, max_loc2[1] + h2 // 2
	else:
		# 边缘检测
		img_rgb = cv2.GaussianBlur(img_rgb, (5, 5), 0)
		canny_img = cv2.Canny(img_rgb, 1, 10)
		H, W = canny_img.shape

		# 消去小跳棋轮廓对边缘检测结果的干扰
		for k in range(max_loc1[1] - 10, max_loc1[1] + 189):
			for b in range(max_loc1[0] - 10, max_loc1[0] + 100):
				canny_img[k][b] = 0

		img_rgb, x_center, y_center = get_center(canny_img)

	# 将图片输出以供调试
	img_rgb = cv2.circle(img_rgb, (x_center, y_center), 10, 255, -1)
	# cv2.rectangle(canny_img, max_loc1, center1_loc, 255, 2)
	cv2.imwrite('last.png', img_rgb)

	distance = (center1_loc[0] - x_center) ** 2 + (center1_loc[1] - y_center) ** 2
	distance = distance ** 0.5
	jump(distance)
	time.sleep(0.5)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
				<pubDate>Fri, 09 Mar 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/tutorial/2018/03/09/weChat-jumping.html</link>
				<guid isPermaLink="true">http://localhost:4000/tutorial/2018/03/09/weChat-jumping.html</guid>
			</item>
		
			<item>
				<title>英语论文写作</title>
				<description>&lt;h1 id=&quot;title&quot;&gt;title&lt;/h1&gt;
&lt;p&gt;  言简意赅，反映论文中心思想&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract–&lt;/h2&gt;
&lt;p&gt;  1.本文、本项目的研究意义，为什么要做这项工作 		
  2.本文的主要工作：用了什么方法，作了哪些研究，做出了什么贡献，得到什么结果。&lt;/p&gt;
&lt;h2 id=&quot;1-introduction使用罗马数字&quot;&gt;1. INTRODUCTION(使用罗马数字)&lt;/h2&gt;
&lt;p&gt;  1.介绍相关背景（芒果检测有什么意义,能用在什么场景，提高农场管理和收获效率，估计产量等）		
  2.前人的工作。有哪些方法，最新的进展（检测方法、技术）（注意引用相关论文）（这些进展相比以前的方法有什么优势）		
  3.本文主要解决了什么问题，主要工作，主要贡献（1. 2. 3.）		
  4.文章剩下部分的组织结构。(Section 2…, Section 3…)&lt;/p&gt;
&lt;h2 id=&quot;2-related-work使用罗马数字&quot;&gt;2. RELATED WORK(使用罗马数字)&lt;/h2&gt;
&lt;p&gt;  1.如何实现检测，检测过程（通用）	 	
  2.相关技术，方法（传统的图像处理方法，机器学习，CNN）		
  3.主要研究问题&lt;/p&gt;
&lt;h2 id=&quot;3-method使用罗马数字&quot;&gt;3. METHOD（使用罗马数字）&lt;/h2&gt;
&lt;p&gt;  1.提出使用的方法，具体介绍&lt;/p&gt;
&lt;h2 id=&quot;4-experiment罗马数字&quot;&gt;4. EXPERIMENT（罗马数字）&lt;/h2&gt;
&lt;p&gt;  1.介绍使用的数据集		
  2.实验过程&lt;/p&gt;
&lt;h2 id=&quot;5-result&quot;&gt;5. RESULT&lt;/h2&gt;
&lt;p&gt;  1.纵向比较，不同参数等		
  2.横向比较，与其他方法的结果对比&lt;/p&gt;
&lt;h2 id=&quot;6-discussion&quot;&gt;6. DISCUSSION&lt;/h2&gt;
&lt;p&gt;  对实验过程和结果的分析&lt;/p&gt;
&lt;h2 id=&quot;7-conclusion&quot;&gt;7. CONCLUSION&lt;/h2&gt;
&lt;p&gt;  1.总结本文的主要工作，实验结果		
  2.本文的不足，未来的工作等&lt;/p&gt;
&lt;h2 id=&quot;references&quot;&gt;REFERENCES&lt;/h2&gt;
</description>
				<pubDate>Mon, 05 Mar 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/paper/2018/03/05/paper-writting.html</link>
				<guid isPermaLink="true">http://localhost:4000/paper/2018/03/05/paper-writting.html</guid>
			</item>
		
			<item>
				<title>目标检测论文小记</title>
				<description>&lt;p&gt;  1、&lt;a href=&quot;/assets/paper/Improve object detection via a multi-feature and multi-task CNN model.pdf&quot;&gt;Improve object detection via a multi-feature and multi-task CNN model&lt;/a&gt;&lt;br /&gt;
主要贡献：多特征（多个卷积层作为ROI）、多任务（检测、分割）以及定义新的重叠损失函数，提高了小目标检测精度，在voc数据集上测试。      &lt;br /&gt;
  2、&lt;a href=&quot;/assets/paper/Graphic logo detection with deep region-based convolutional networks.pdf&quot;&gt;Graphic logo detection with deep region-based convolutional networks&lt;/a&gt; &lt;br /&gt;
主要贡献：a.数据集：&lt;a href=&quot;http://www.multimedia-computing.de/flickrlogos/&quot;&gt;FlickrLogo-32 dataset&lt;/a&gt;   b.组合不同的CNN模型和fast rcnn，并使用了迁移学习   c.使用K-means方法对训练数据进行聚类，设置超参数。  d.改变fast rcnn参数：anchor scales, ratios&lt;/p&gt;

&lt;p&gt;  2、&lt;a href=&quot;/assets/paper/Forward Vehicle Detection Based on Incremental Learning and Fast R-CNN.pdf&quot;&gt;Forward Vehicle Detection Based on Incremental Learning and Fast R-CNN&lt;/a&gt; &lt;br /&gt;
主要贡献：a.数据集：&lt;a href=&quot;http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d&quot;&gt; KITTI dataset&lt;/a&gt;  b.训练模型：fast rcnn与不同的cnn模型       &lt;br /&gt;
  3、&lt;a href=&quot;/assets/paper/CityPersons-A Diverse Dataset for Pedestrian Detection.pdf&quot;&gt;CityPersons-A Diverse Dataset for Pedestrian Detection&lt;/a&gt;  &lt;br /&gt;
主要贡献：数据集：&lt;a href=&quot;https://bitbucket.org/shanshanzhang/citypersons&quot;&gt;CityPerson&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Sat, 03 Mar 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/paper/2018/03/03/detection-papers-note.html</link>
				<guid isPermaLink="true">http://localhost:4000/paper/2018/03/03/detection-papers-note.html</guid>
			</item>
		
			<item>
				<title>python代码</title>
				<description>&lt;h3 id=&quot;1图像增强对颜色分量进行处理&quot;&gt;1、图像增强（对颜色分量进行处理）&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import os
		import cv2
		import numpy as np

		dir = r&quot;JPEGImages/&quot;
		list = os.listdir(dir)
		cnt =0

		for i in range(0, len(list)):
			print(list[i])
			img = cv2.imread(dir+list[i])
			img_tmp = img.copy()
			img2 = img.copy()
			img_tmp = img_tmp.dot((0.05, 0.35, 0.6))
			#print(img_tmp.shape)
			img[:,:,0] = img_tmp
			#img[:,:,1] = img_tmp
			#img[:,:,2] = img_tmp
			#print(img.shape)
			#cv2.imshow('img', img)
			#cv2.imshow('aug', img2)
			#cv2.waitKey(0)
			cv2.imwrite(r&quot;aug/&quot;+list[i], img)
			cnt = cnt + 1
		print(cnt)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2生成标签文件将csv格式的文件存储的标签数据转换为固定格式的txt文件或者将数据处理后写入到新的csv格式文件&quot;&gt;2、生成标签文件。将csv格式的文件存储的标签数据转换为固定格式的txt文件或者将数据处理后写入到新的csv格式文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import csv
		import os

		dir = r&quot;test-annotations-csv/&quot;
		list = os.listdir(dir)

		flag = 0
		category = 'apple'
		top_left_x = 0
		top_left_y = 0
		bottom_right_x = 0
		bottom_right_y = 0

		txt = open(&quot;label.txt&quot;, 'w')

		for i in range(0,len(list)):  #len(list)
			img_file_name = list[i].rstrip('.csv') + '.png'
			print(img_file_name)
			path = os.path.join(dir,list[i])
			new_csv = open(r'aug_label_csv_test/'+list[i], 'w', newline='')
			writer = csv.writer(new_csv)
			writer.writerow(['#item', 'c-x', 'c-y', 'radius', 'label'])
			if os.path.isfile(path):
				out = open(path,'r')
				read_csv = csv.reader(out,dialect='excel')
				for line in read_csv:     #循环输出csv中的所有数据
					if flag == 0:
						flag = flag + 1
						continue
					flag = flag + 1
					#print(line)
					if line[4] == '1':
						category = 'apple'
						top_left_x = (int)(float(line[1]) + float(line[3])) if (int)(float(line[1]) + float(line[3])) &amp;lt; 307 else 307
						top_left_x = 308 - top_left_x
						top_left_y = (int)(float(line[2]) - float(line[3])) if (int)(float(line[2]) - float(line[3])) &amp;gt; 1 else 1
						bottom_right_x = (int)(float(line[1]) - float(line[3])) if (int)(float(line[1]) - float(line[3])) &amp;gt; 0 else 0
						bottom_right_x = 308 - bottom_right_x
						bottom_right_y = (int)(float(line[2]) + float(line[3])) if (int)(float(line[2]) + float(line[3])) &amp;lt; 202 else 202
						write_str = img_file_name + ' ' + category + ' ' + str(top_left_x) +' ' + str(top_left_y) + ' ' + str(bottom_right_x) + ' ' + str(bottom_right_y) + '\n'
						txt.write(write_str)
						c_x = float((top_left_x+bottom_right_x)/2)
						c_y = float((top_left_y+bottom_right_y)/2)
						radius = float((bottom_right_x+bottom_right_y-top_left_x-top_left_y)/4)
						writer.writerow([str(flag-2), str(c_x), str(c_y), str(radius), '1'])
				#print(flag)
				if flag == 1:
					print(&quot;no apples&quot;)
					os.exit()
				flag = 0
				out.close()
			new_csv.close()
		txt.close() 
		print(len(list))			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3图像增强水平翻转&quot;&gt;3、图像增强（水平翻转）&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import os
		import cv2

		dir = r&quot;test_images/&quot;
		list = os.listdir(dir)
		cnt = 0

		for i in range(0,len(list)):  #len(list)
			img_file_name = list[i]
			print(img_file_name)
			img = cv2.imread(dir+img_file_name)
			new_img = cv2.flip(img, 1)
			cv2.imwrite(r&quot;aug_images_test/&quot;+img_file_name, new_img)
			cnt += 1
		print('all ', cnt)			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4计算一幅图像三个颜色通道各自的平均值&quot;&gt;4、计算一幅图像三个颜色通道各自的平均值&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import cv2
		import os
		import numpy as np

		dir = r'JPEGImages/'
		list = os.listdir(dir)

		R_sum = 0
		G_sum = 0
		B_sum = 0
		im_num = 0

		for im_name in list:
			im_num += 1
			img = cv2.imread(dir+im_name)
			imgr = img[:,:,2]
			imgg = img[:,:,1]
			imgb = img[:,:,0]
			R_sum += np.sum(imgr) / 308 / 202
			G_sum += np.sum(imgg) / 308 / 202
			B_sum += np.sum(imgb) / 308 / 202
			#print R_sum, G_sum, B_sum
		R_sum /= im_num
		G_sum /= im_num
		B_sum /= im_num
		print R_sum, G_sum, B_sum			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;5根据csv文件的标签数据在原图上画出标定框&quot;&gt;5、根据csv文件的标签数据在原图上画出标定框&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import csv
		import os
		from PIL import Image, ImageDraw

		source_dir = r'apple/'
		dest_dir = r'apple-gt/'

		list = os.listdir(source_dir)
		for file_name in list:
			print file_name
			file_name_no_ext = file_name.rstrip('.png')
			img = Image.open(source_dir+file_name)
			draw = ImageDraw.Draw(img)
			csv_out = open(r'test-annotations-csv/'+file_name_no_ext+'.csv', 'r')
			read_csv = csv.reader(csv_out, dialect='excel')
			csv_line_num = 0
			for line in read_csv:
				if csv_line_num == 0:
					csv_line_num += 1
					continue
				xminT = (int)(float(line[1]) - float(line[3])) if (int)(float(line[1]) - float(line[3])) &amp;gt; 1 else 1
				yminT = (int)(float(line[2]) - float(line[3])) if (int)(float(line[2]) - float(line[3])) &amp;gt; 1 else 1
				xmaxT = (int)(float(line[1]) + float(line[3])) if (int)(float(line[1]) + float(line[3])) &amp;lt; 308 else 308
				ymaxT = (int)(float(line[2]) + float(line[3])) if (int)(float(line[2]) + float(line[3])) &amp;lt; 202 else 202
				draw.rectangle([xminT, yminT, xmaxT, ymaxT], outline=(0, 0, 255))
			csv_out.close()
			img.save(dest_dir+file_name)			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;6根据txt文件保存了文件名批量复制文件&quot;&gt;6、根据txt文件（保存了文件名）批量复制文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import os
		import shutil

		dir = r'test-annotations-csv/'
		txt = open(r'ImageSets/Main/test.txt')
		lines = txt.readlines()
		for line in lines:
			line = line.strip('\r\n') + '.csv'
			print(line)
			shutil.copyfile(r'annotations-csv/'+line, dir + line)
		txt.close()			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;7随机读取txt文件中的若干行&quot;&gt;7、随机读取txt文件中的若干行&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import random
		import linecache
		import shutil

		txt = open(&quot;random-select/label.txt&quot;, 'w')
		resultList=random.sample(range(0,789),150)
		for i in range(0, 150):
			theline = linecache.getline(r'ImageSets/Main/train.txt', resultList[i]).strip('\n')
			print(theline)
			txt.write(theline+'\n')
			shutil.copyfile(r'Annotations/'+theline+'.xml', r&quot;random-select/Annotations/&quot;+theline+'.xml')
			shutil.copyfile(r&quot;JPEGImages/&quot;+theline+'.png', r&quot;random-select/JPEGImages/&quot;+theline+'.png')
		txt.close()			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;8读取txt文件&quot;&gt;8、读取txt文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import os

		txt = open(r'test.txt')
		new_txt = open(r'test1.txt', 'w')
		lines = txt.readlines()
		#print lines.strip('\n')
		for line2 in lines:
			new_txt.write(line2.strip('\r\n')+'\n')
		txt.close()
		new_txt.close()			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;9读取csv文件&quot;&gt;9、读取csv文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import csv
		import os
		import shutil


		dir = r&quot;annotations-csv/&quot;
		list = os.listdir(dir)

		flag = 0

		for i in range(0,len(list)):  #len(list)
			file_name_no_ext = list[i].rstrip('.csv')
			print(file_name_no_ext)
			path = os.path.join(dir,list[i])
			if os.path.isfile(path):
				out = open(path,'r')
				read_csv = csv.reader(out,dialect='excel')
				for line in read_csv:     #循环输出csv中的所有数据
					if flag == 0:
						flag = flag + 1
						continue
					flag = flag + 1
				if flag &amp;gt; 1:
					shutil.copyfile(path, r&quot;all-have-apples/annotations-csv/&quot;+file_name_no_ext+'.csv')
					shutil.copyfile(r&quot;images/&quot;+file_name_no_ext+'.png', r&quot;all-have-apples/images/&quot;+file_name_no_ext+'.png')
				flag = 0
				out.close()
		print(len(list))			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;9文件批量重命名000001&quot;&gt;9、文件批量重命名（000001.*）&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import os

		for i in range(1870 * 1 + 1, 1870 * 2 + 1):
			index = str(i).zfill(6)
			os.rename('camera4/period14_camera4/%d.png' % i, 'camera4/period14_camera4/%s.png' % index)   #重命名
		print('ok')
		#        print file.split('.')[-1]			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;10除去txt文件中的空行&quot;&gt;10、除去txt文件中的空行&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import sys  

		f=open('tmp.txt', 'r')  
		fnew=open('_new.txt','w') #将结果存入新的文本中 
		lines =  f.readlines()
		for line in lines:   #对每一行先删除空格，\n等无用的字符，再检查此行是否长度为0  
			#print(&quot;:&quot;+line)
			if line.strip():   
				fnew.write(line) 
		print('ok')
		f.close()  
		fnew.close() 			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;11opencv提取前景&quot;&gt;11、opencv提取前景&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import numpy as np
		import cv2

		#cap = cv2.VideoCapture('Video_001.avi')
		#cap = cv2.VideoCapture(0)
		kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
		fgbg = cv2.createBackgroundSubtractorMOG2(False)
		cv2.namedWindow(&quot;sourceImg&quot;)
		cv2.namedWindow(&quot;fgmask&quot;)
		count = 0
		for i in range(1, 23):
			frame = cv2.imread(&quot;ball_annotated/camera1_20080409T183943+02_frame%d.png&quot; % (i))
			#ret, frame = cap.read()
			fgmask = fgbg.apply(frame)
			fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)
			cv2.imshow('sourceImg', frame)
			cv2.imshow('fgmask', fgmask)
			#count = i % 10
			#if not count:
			cv2.imwrite(&quot;2.fg/camera1_20080409T183943+02_frame%d_fg.png&quot; % (i), fgmask)
			k = cv2.waitKey(100) &amp;amp; 0xff
			#if k == 27:
				#break
		#cap.release()
		cv2.destroyAllWindows()			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;12xml文件转换成txt文件&quot;&gt;12、xml文件转换成txt文件&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		&lt;span class=&quot;c&quot;&gt;#!/usr/bin/evn python&lt;/span&gt;
		&lt;span class=&quot;c&quot;&gt;# coding:utf-8&lt;/span&gt;
		&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
			&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;xml.etree.cElementTree&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ET&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ImportError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
			&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;xml.etree.ElementTree&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ET&lt;/span&gt;
		&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;

		&lt;span class=&quot;n&quot;&gt;xml_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;r&quot;D:\Python\PythonProjects\333_xml&quot;&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;xml_paths&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;listdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;
						 &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endswith&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;.xml&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

		&lt;span class=&quot;n&quot;&gt;strTemp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 将txt文件清空&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;mytxt.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;w&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strTemp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xml_path&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xml_paths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xml_path&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ET&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 打开xml文档&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getroot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 获得root节点&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;
			&lt;span class=&quot;s&quot;&gt;&quot;*&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'filename'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
			&lt;span class=&quot;c&quot;&gt;#filename = filename[:-4]&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;

			&lt;span class=&quot;c&quot;&gt;########################################&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 找到root节点下的size节点&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'width'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 子节点下节点width的值&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'height'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 子节点下节点height的值&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;
			&lt;span class=&quot;c&quot;&gt;########################################&lt;/span&gt;

			&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'object'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 找到root节点下的所有object节点&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 子节点下节点name的值&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;bndbox&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bndbox'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 子节点下属性bndbox的值&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;xmin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bndbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'xmin'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bndbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ymin'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;xmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bndbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'xmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bndbox&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ymax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;xmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;

			&lt;span class=&quot;n&quot;&gt;strTemp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'.png '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'basketball'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ymin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;

			&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xml_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;mytxt.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strTemp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;			
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;13图像数据增强方法&quot;&gt;13、图像数据增强方法&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		# -*- coding:utf-8 -*-  
		&quot;&quot;&quot;数据增强 
		   1. 翻转变换 flip 
		   2. 随机修剪 random crop 
		   3. 色彩抖动 color jittering 
		   4. 平移变换 shift 
		   5. 尺度变换 scale 
		   6. 对比度变换 contrast 
		   7. 噪声扰动 noise 
		   8. 旋转变换/反射变换 Rotation/reflection 
		   author: XiJun.Gong 
		   date:2016-11-29 
		&quot;&quot;&quot;  

		from PIL import Image, ImageEnhance, ImageOps, ImageFile  
		import numpy as np  
		import random  
		import threading, os, time  
		import logging  
		import cv2  
		logger = logging.getLogger(__name__)  
		ImageFile.LOAD_TRUNCATED_IMAGES = True  


		class DataAugmentation:  
			&quot;&quot;&quot; 
			包含数据增强的八种方式 
			&quot;&quot;&quot;  


			def __init__(self):  
				pass  

			@staticmethod  
			def openImage(image):  
				return Image.open(image, mode=&quot;r&quot;)  

			@staticmethod  
			def randomRotation(image, mode=Image.BICUBIC):  
				&quot;&quot;&quot; 
				 对图像进行随机任意角度(0~360度)旋转 
				:param mode 邻近插值,双线性插值,双三次B样条插值(default) 
				:param image PIL的图像image 
				:return: 旋转转之后的图像 
				&quot;&quot;&quot;  
				random_angle = np.random.randint(1, 360)  
				return image.rotate(random_angle, mode)  
				#return image.rotate(180, mode)  

			@staticmethod  
			def randomFlip(image):  
				#图像翻转（类似于镜像，镜子中的自己）  
				#FLIP_LEFT_RIGHT,左右翻转  
				#FLIP_TOP_BOTTOM,上下翻转  
				#ROTATE_90, ROTATE_180, or ROTATE_270.按照角度进行旋转，与randomRotate()功能类似  
				return image.transpose(Image.FLIP_LEFT_RIGHT)  

			@staticmethod  
			def Tranform(image):  
				#t图像变换  
				#im.transform(size, method, data) ⇒ image  

				#im.transform(size, method, data, filter) ⇒ image  
				#1：image.transform((300,300), Image.EXTENT, (0, 0, 300, 300))   
				#   变量data为指定输入图像中两个坐标点的4元组(x0,y0,x1,y1)。  
				#   输出图像为这两个坐标点之间像素的采样结果。  
				#   例如，如果输入图像的(x0,y0)为输出图像的（0，0）点，(x1,y1)则与变量size一样。  
				#   这个方法可以用于在当前图像中裁剪，放大，缩小或者镜像一个任意的长方形。  
				#   它比方法crop()稍慢，但是与resize操作一样快。  
				#2：image.transform((300,300), Image.AFFINE, (1, 2,3, 2, 1,4))  
				#   变量data是一个6元组(a,b,c,d,e,f)，包含一个仿射变换矩阵的第一个两行。  
				#   输出图像中的每一个像素（x，y），新值由输入图像的位置（ax+by+c, dx+ey+f）的像素产生，  
				#   使用最接近的像素进行近似。这个方法用于原始图像的缩放、转换、旋转和裁剪。  
				#3: image.transform((300,300), Image.QUAD, (0,0,0,500,600,500,600,0))  
				#   变量data是一个8元组(x0,y0,x1,y1,x2,y2,x3,y3)，它包括源四边形的左上，左下，右下和右上四个角。  
				#4: image.transform((300,300), Image.MESH, ())  
				#   与QUAD类似，但是变量data是目标长方形和对应源四边形的list。  
				#5: image.transform((300,300), Image.PERSPECTIVE, (1,2,3,2,1,6,1,2))  
				#   变量data是一个8元组(a,b,c,d,e,f,g,h)，包括一个透视变换的系数。  
				#   对于输出图像中的每个像素点，新的值来自于输入图像的位置的(a x + b y + c)/(g x + h y + 1),  
				#   (d x+ e y + f)/(g x + h y + 1)像素，使用最接近的像素进行近似。  
				#   这个方法用于原始图像的2D透视。  
				return image.transform((300,300), Image.EXTENT, (0, 0, 300, 300))  

			@staticmethod  
			def randomCrop(image):  
				&quot;&quot;&quot; 
				对图像随意剪切,考虑到图像大小范围(68,68),使用一个一个大于(36*36)的窗口进行截图 
				:param image: PIL的图像image 
				:return: 剪切之后的图像 

				&quot;&quot;&quot;  
				image_width = image.size[0]  
				image_height = image.size[1]  
				crop_win_size = np.random.randint(40, 68)  
				random_region = (  
					(image_width - crop_win_size) &amp;gt;&amp;gt; 1, (image_height - crop_win_size) &amp;gt;&amp;gt; 1, (image_width + crop_win_size) &amp;gt;&amp;gt; 1,  
					(image_height + crop_win_size) &amp;gt;&amp;gt; 1)  
				return image.crop(random_region)  

			@staticmethod  
			def randomColor(image):  
				&quot;&quot;&quot; 
				对图像进行颜色抖动 
				:param image: PIL的图像image 
				:return: 有颜色色差的图像image 
				&quot;&quot;&quot;  
				random_factor = np.random.randint(0, 31) / 10.  # 随机因子  
				color_image = ImageEnhance.Color(image).enhance(random_factor)  # 调整图像的饱和度  
				random_factor = np.random.randint(10, 21) / 10.  # 随机因子  
				brightness_image = ImageEnhance.Brightness(color_image).enhance(random_factor)  # 调整图像的亮度  
				random_factor = np.random.randint(10, 21) / 10.  # 随机因1子  
				contrast_image = ImageEnhance.Contrast(brightness_image).enhance(random_factor)  # 调整图像对比度  
				random_factor = np.random.randint(0, 31) / 10.  # 随机因子  
				return ImageEnhance.Sharpness(contrast_image).enhance(random_factor)  # 调整图像锐度  

			@staticmethod  
			def randomGaussian(image, mean=0.2, sigma=0.3):  
				&quot;&quot;&quot; 
				 对图像进行高斯噪声处理 
				:param image: 
				:return: 
				&quot;&quot;&quot;  

				def gaussianNoisy(im, mean=0.2, sigma=0.3):  
					&quot;&quot;&quot; 
					对图像做高斯噪音处理 
					:param im: 单通道图像 
					:param mean: 偏移量 
					:param sigma: 标准差 
					:return: 
					&quot;&quot;&quot;  
					for _i in range(len(im)):  
						im[_i] += random.gauss(mean, sigma)  
					return im  

				# 将图像转化成数组  
				img = np.asarray(image)  
				img.flags.writeable = True  # 将数组改为读写模式  
				width, height = img.shape[:2]  
				img_r = gaussianNoisy(img[:, :, 0].flatten(), mean, sigma)  
				img_g = gaussianNoisy(img[:, :, 1].flatten(), mean, sigma)  
				img_b = gaussianNoisy(img[:, :, 2].flatten(), mean, sigma)  
				img[:, :, 0] = img_r.reshape([width, height])  
				img[:, :, 1] = img_g.reshape([width, height])  
				img[:, :, 2] = img_b.reshape([width, height])  
				return Image.fromarray(np.uint8(img))  

			@staticmethod  
			def saveImage(image, path):  
				image.save(path)  


		def makeDir(path):  
			try:  
				if not os.path.exists(path):  
					if not os.path.isfile(path):  
						# os.mkdir(path)  
						os.makedirs(path)  
					return 0  
				else:  
					return 1  
			except Exception, e:  
				print str(e)  
				return -2  


		def imageOps(func_name, image, des_path, file_name, times=5):  
			#funcMap = {&quot;randomRotation&quot;: DataAugmentation.randomRotation,  
			#           &quot;randomCrop&quot;: DataAugmentation.randomCrop,  
			#           &quot;randomColor&quot;: DataAugmentation.randomColor,  
			#           &quot;randomGaussian&quot;: DataAugmentation.randomGaussian  
			#           &quot;randomFlip&quot;:DataAugmentation.randomFlip,  
			#           }  
			funcMap = {  
					   &quot;Tranform&quot;:DataAugmentation.Tranform  
					   }  
			if funcMap.get(func_name) is None:  
				logger.error(&quot;%s is not exist&quot;, func_name)  
				return -1  

			for _i in range(0, times, 1):  
				new_image = funcMap[func_name](image)  
				DataAugmentation.saveImage(new_image, os.path.join(des_path, func_name + str(_i) + file_name))  


		#opsList = {&quot;randomFlip&quot;,&quot;randomRotation&quot;, &quot;randomCrop&quot;, &quot;randomColor&quot;, &quot;randomGaussian&quot;}  
		opsList = { &quot;Tranform&quot;}  

		def threadOPS(path, new_path):  
			&quot;&quot;&quot; 
			多线程处理事务 
			:param src_path: 资源文件 
			:param des_path: 目的地文件 
			:return: 
			&quot;&quot;&quot;  
			if os.path.isdir(path):  
				img_names = os.listdir(path)  
			else:  
				img_names = [path]  
			for img_name in img_names:  
				print img_name  
				tmp_img_name = os.path.join(path, img_name)  
				if os.path.isdir(tmp_img_name):  
					if makeDir(os.path.join(new_path, img_name)) != -1:  
						threadOPS(tmp_img_name, os.path.join(new_path, img_name))  
					else:  
						print 'create new dir failure'  
						return -1  
						# os.removedirs(tmp_img_name)  
				elif tmp_img_name.split('.')[1] != &quot;DS_Store&quot;:  
					# 读取文件并进行操作  
					image = DataAugmentation.openImage(tmp_img_name)  
					threadImage = [0] * 5  
					_index = 0  
					for ops_name in opsList:  
						threadImage[_index] = threading.Thread(target=imageOps,  
															   args=(ops_name, image, new_path, img_name,))  
						threadImage[_index].start()  
						_index += 1  
						time.sleep(0.2)  


		if __name__ == '__main__':  
			threadOPS(&quot;D:\datasets\dataArgument\JPEGImages&quot;,  
					  &quot;D:\datasets\dataArgument\Dealed_JPEGImages&quot;)  		
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;14从一个voc数据集创建多个训练子集只改变训练样本的数量&quot;&gt;14、从一个VOC数据集创建多个训练子集（只改变训练样本的数量）&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;		import random 
		import linecache
		import shutil
		import os

		source_txt_dir = r'ImageSets/Main/'
		source_annotations_dir = r'Annotations/'
		source_images_dir = r'JPEGImages/'
		dest_root_dir = r'manyDatasets/'

		for image_num in range(50, 751, 50):

			#create dir
			one_dataset_dir = dest_root_dir + str(image_num)
			Annotations_dir = one_dataset_dir+'/Annotations/'
			ImageSets_dir_up = one_dataset_dir+'/ImageSets/'
			ImageSets_dir = one_dataset_dir+'/ImageSets/Main/'
			JPEGImages_dir = one_dataset_dir+'/JPEGImages/'

			is_exist_dir = os.path.exists(one_dataset_dir)  #dataset dir
			if not is_exist_dir:
				os.mkdir(one_dataset_dir)
			is_exist_dir = os.path.exists(Annotations_dir)  #Annotations dir
			if not is_exist_dir:
				os.mkdir(Annotations_dir)
			is_exist_dir = os.path.exists(ImageSets_dir_up)  #ImageSets dir
			if not is_exist_dir:
				os.mkdir(ImageSets_dir_up)
				is_exist_dir = os.path.exists(ImageSets_dir)  #ImageSets dir
			if not is_exist_dir:
				os.mkdir(ImageSets_dir)
			is_exist_dir = os.path.exists(JPEGImages_dir)  #JPEGImages dir
			if not is_exist_dir:
				os.mkdir(JPEGImages_dir)

			#create new train.txt trainval.txt
			new_train = open(ImageSets_dir+'train.txt', 'w')
			new_trainval = open(ImageSets_dir+'trainval.txt', 'w')

			#read source train.txt
			result_list = random.sample(range(1, 789), image_num)  #image_num
			for i in range(0, image_num):
				file_name_no_ext = linecache.getline(source_txt_dir+'train.txt', result_list[i]).rstrip('\r\n')
				print file_name_no_ext

				#write train.txt
				new_train.write(file_name_no_ext+'\n')
				new_trainval.write(file_name_no_ext+'\n')

				#copy annotations file
				shutil.copyfile(source_annotations_dir+file_name_no_ext+'.xml', Annotations_dir+file_name_no_ext+'.xml')
				#copy images
				shutil.copyfile(source_images_dir+file_name_no_ext+'.png', JPEGImages_dir+file_name_no_ext+'.png')

			new_train.close()
			#write test.txt
			source_test = open(source_txt_dir+'test.txt', 'r')
			new_test = open(ImageSets_dir+'test.txt', 'w')
			lines = source_test.readlines()
			for line in lines:
				new_test.write(line.rstrip('\r\n')+'\n')
				#copy annotations file
				shutil.copyfile(source_annotations_dir+line.rstrip('\r\n')+'.xml', Annotations_dir+line.rstrip('\r\n')+'.xml')
				#copy images
				shutil.copyfile(source_images_dir+line.rstrip('\r\n')+'.png', JPEGImages_dir+line.rstrip('\r\n')+'.png')
			source_test.close()
			new_test.close()

			#write val.txt
			source_val = open(source_txt_dir+'val.txt', 'r')
			new_val = open(ImageSets_dir+'val.txt', 'w')
			lines = source_val.readlines()
			for line in lines:
				new_val.write(line.rstrip('\r\n')+'\n')
				#copy annotations file
				shutil.copyfile(source_annotations_dir+line.rstrip('\r\n')+'.xml', Annotations_dir+line.rstrip('\r\n')+'.xml')
				#copy images
				shutil.copyfile(source_images_dir+line.rstrip('\r\n')+'.png', JPEGImages_dir+line.rstrip('\r\n')+'.png')
			source_val.close()
			new_val.close()

			val = open(ImageSets_dir+'val.txt', 'r')
			lines = val.readlines()
			for line in lines:
				new_trainval.write(line.rstrip('\r\n')+'\n')    #copy val to trainval
			val.close()
			new_trainval.close()				
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
				<pubDate>Sun, 28 Jan 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/material/2018/01/28/python-scripts.html</link>
				<guid isPermaLink="true">http://localhost:4000/material/2018/01/28/python-scripts.html</guid>
			</item>
		
			<item>
				<title>rcnn用于小目标检测</title>
				<description>&lt;h1 id=&quot;论文组织结构&quot;&gt;论文组织结构&lt;/h1&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;  说明现有检测方法的不足：难以检测小目标。提出本文的算法：a context model and a small region proposal generator.&lt;/p&gt;
&lt;h2 id=&quot;1-介绍&quot;&gt;1. 介绍&lt;/h2&gt;
&lt;p&gt;  介绍现有方法的不足以及小目标检测的困难。提出算法。1.1 现有方法、数据集准备。1.2 贡献。&lt;/p&gt;
&lt;h2 id=&quot;2-小物体数据集&quot;&gt;2. 小物体数据集&lt;/h2&gt;
&lt;p&gt;  介绍自己的小物体数据集。从coco和SUN数据集中选取较小的物体的类，如鼠标、电话等。&lt;/p&gt;
&lt;h2 id=&quot;3-rcnn&quot;&gt;3. rcnn&lt;/h2&gt;
&lt;p&gt;  介绍rcnn。&lt;/p&gt;
&lt;h3 id=&quot;31-生成小的proposal&quot;&gt;3.1 生成小的proposal。&lt;/h3&gt;
&lt;p&gt;  存在的问题：rpn生成的anchors太大。选用小的anchors：16,40,100.把rpn网络接到conv4_3之后。&lt;/p&gt;
&lt;h3 id=&quot;32-上采样&quot;&gt;3.2 上采样&lt;/h3&gt;
&lt;h3 id=&quot;33-上下文&quot;&gt;3.3 上下文&lt;/h3&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h2 id=&quot;4-实验设计和结果&quot;&gt;4. 实验设计和结果&lt;/h2&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h2 id=&quot;5-结论&quot;&gt;5. 结论&lt;/h2&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h1 id=&quot;主要算法&quot;&gt;主要算法&lt;/h1&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h1 id=&quot;重要参考文献&quot;&gt;重要参考文献&lt;/h1&gt;

&lt;h1 id=&quot;重要语句&quot;&gt;重要语句&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;/assets/paper/.pdf&quot;&gt;论文原文&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Fri, 19 Jan 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/paper/2018/01/19/rcnn-small-object.html</link>
				<guid isPermaLink="true">http://localhost:4000/paper/2018/01/19/rcnn-small-object.html</guid>
			</item>
		
			<item>
				<title>基于faster-rcnn的小目标检测</title>
				<description>&lt;h1 id=&quot;论文组织结构&quot;&gt;论文组织结构&lt;/h1&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;  介绍文章的主要内容：faster-rcnn，不足。课题，自己的改进，结果。&lt;/p&gt;
&lt;h2 id=&quot;1-介绍&quot;&gt;1. 介绍&lt;/h2&gt;
&lt;p&gt;  1. 现有的检测方法：faster-rcnn、下采样。2. 现状：企业logo检测的问题。 3. 本文的贡献。&lt;/p&gt;
&lt;h2 id=&quot;2-相关工作&quot;&gt;2. 相关工作&lt;/h2&gt;
&lt;p&gt;  介绍前人工作，其他算法、文献&lt;/p&gt;
&lt;h2 id=&quot;3-faster-rcnn小物体检测&quot;&gt;3. faster-rcnn小物体检测&lt;/h2&gt;
&lt;p&gt;  论文主体部分。&lt;/p&gt;
&lt;h2 id=&quot;4-集成的检测算法&quot;&gt;4. 集成的检测算法&lt;/h2&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h2 id=&quot;5-结论&quot;&gt;5. 结论&lt;/h2&gt;
&lt;p&gt;  &lt;/p&gt;
&lt;h1 id=&quot;主要算法&quot;&gt;主要算法&lt;/h1&gt;
&lt;p&gt;  通过比较在不同conv层以及不同anchors尺度下的rpn性能，得出提升小目标检测精度的方法。在conv4之后加了一个分支用于RPN，提升了rpn的精度。&lt;/p&gt;
&lt;h1 id=&quot;重要参考文献&quot;&gt;重要参考文献&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn:
Towards real-time object detection with region proposal
networks,” IEEE PAMI, 2016.&lt;/li&gt;
  &lt;li&gt;Zhangyang Wang, Shiyu Chang, Yingzhen Yang, Ding
Liu, and Thomas S. Huang, “Studying very low res-
olution recognition using deep networks,” CoRR, vol.
abs/1601.04153, 2016.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;重要语句&quot;&gt;重要语句&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;/assets/paper/A CLOSER LOOK: SMALL OBJECT DETECTION IN FASTER R-CNN.pdf&quot;&gt;论文原文&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Thu, 18 Jan 2018 00:00:00 +0800</pubDate>
				<link>http://localhost:4000/paper/2018/01/18/small-object-detection-faster-rcnn.html</link>
				<guid isPermaLink="true">http://localhost:4000/paper/2018/01/18/small-object-detection-faster-rcnn.html</guid>
			</item>
		
	</channel>
</rss>
